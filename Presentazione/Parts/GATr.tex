\begin{frame}
    \Huge GATr
    \rule{\textwidth}{.25pt}
    \small{Autore: Alin Habasescu Marin}
\end{frame}
\begin{frame}{GATr - Introduzione}
    In diverse situazioni si ha a che fare con dati di natura geometrica, soprattutto
    in ambiti scientifici ed ingegneristici. Il vantaggio di utilizzare dati geometrici
    risiede nel comportamento definito dei dati sotto trasformazioni ben definite, come 
    rotazioni e traslazioni.

    Con l'obiettivo di sfruttare al meglio questi dati, si introduce il 
    Geometric Algebra Transformer (GATr), un'architettura di rete general-purpose 
    che sfrutta dati geometrici. 
\end{frame}

\begin{frame}{GATr - Idee Chiave}
    GATr integra tre concetti fondamentali:
    \begin{itemize}
        \item \textbf{Algebra Geometrica}
        \item \textbf{Equivarianza}
        \item \textbf{Transformer}
    \end{itemize}
\end{frame}

\begin{frame}{Fondamenti di Algebra Geometrica: Strumenti e Applicazioni}

    Per rappresentare oggetti tridimensionali e applicare rotazioni e traslazioni su di 
    essi, la 3D GA non è sufficiente, poichè i multivettori dell'algebra tradizionale 
    possono rappresentare solo sottospazi lineari che passano per l'origine e rotazioni 
    intorno ad essa. 

    GATr consente di rappresentare i dati come multivettori dell'algebra geometrica 
    proiettiva \(\mathbb{G}_{3,0,1}\). In pratica lo spazio di interesse viene inserito 
    in uno spazio di dimensione superiore, aggiungendo una quarta coordinata omogenea 
    \(x_0 \Vb{e}_{0}\), ottenendo un'algebra di dimensione \(2^4 = 16\) dimensioni, capace di 
    rappresentare vari tipi geometrici e pose \(E(3)\).
\end{frame}

\begin{frame}{Fondamenti di Algebra Geometrica: Strumenti e Applicazioni}

    Nell’algebra geometrica, un vettore \( \Vb{u} \) può agire come operatore riflettendo 
    altri elementi nel piano ortogonale a \( \Vb{u} \). 
    Poiché ogni trasformazione ortogonale può essere espressa come una sequenza di riflessioni, 
    possiamo rappresentare qualsiasi trasformazione come prodotto geometrico di vettori 
    unitari, detti \textit{versori}  \( u = u_1 \cdots u_k \).

    Il prodotto di versori unitari genera un gruppo, chiamato \textit{Pin group}, 
    in cui i versori unitari si comportano come propri inversi (\( u^2 = 1 \)). 
    I prodotti di un numero pari di riflessioni formano il \textit{Spin group}. 
    Nell’algebra geometrica proiettiva \( \mathbb{G}_{3,0,1} \), questi gruppi 
    permettono di coprire le trasformazioni \( E(3) \) e \( SE(3) \), rispettivamente.
\end{frame}

\begin{frame}{Algebra Geometrica: Prodotto Sandwich}
    Le simmetrie tridimensionali (rotazioni, traslazioni, riflessioni) si rappresentano 
    con i multivettori di \( \mathbb{G}_{3,0,1} \). Il prodotto \textit{sandwich} applica 
    un versore \( u \) ad un elemento \( x \):

    \begin{equation}
        \rho_u(x) = 
        \begin{cases}
            u x u^{-1} & \text{se } u \text{ è pari} \\
            u x \hat{u}^{-1} & \text{se } u \text{ è dispari}
        \end{cases}
    \label{eq:4}
    \end{equation}

    dove \( \hat{x} \) è l'involuzione di grado, che inverte il segno degli elementi 
    dispari (come vettori e trivettori) e lascia invariati quelli di grado pari. 
    Questo prodotto fornisce una rappresentazione lineare dei gruppi \textit{Pin} e 
    \textit{Spin}.

\end{frame}

\begin{frame}{Fondamenti di Algebra Geometrica: Strumenti e Applicazioni}

    Per rappresentare oggetti 3D, i piani sono descritti da vettori, e l'intersezione 
    di due oggetti geometrici è data dal prodotto wedge delle loro rappresentazioni. 
    Si crea una dualità tra oggetti e operatori, in cui gli oggetti 
    si comportano come trasformazioni che li lasciano invariati.

    La Tabella mostra una corrispondenza tra queste rappresentazioni, che risultano 
    compatibili con il prodotto \textit{sandwich} utilizzato per le trasformazioni.

\end{frame}

\begin{frame}{Algebra Geometrica: Tabella di Oggetti e Operatori}
    \begin{figure}
        \centering
        \includegraphics[width=1\textwidth]{../Images/relazioneOggettiOperatori.png}
        \caption{La tabella mostra la relazione tra oggetti geometrici fondamentali 
        (come vettori, piani) e gli operatori che li trasformano. Aiuta a visualizzare come 
        diversi tipi di oggetti interagiscono tra loro tramite operazioni geometriche.}
        \label{fig:relazioneOggettiOperatori}
    \end{figure}
\end{frame}

\begin{frame}{Equivarianza}
    GATr è progettato per essere equivariante rispetto al gruppo di simmetria \(E(3)\), 
    che descrive le trasformazioni nello spazio tridimensionale. 

    A tale scopo, sono state sviluppate diverse nuove primitive 
    \(E(3)\)-equivarianti, tra cui mappe lineari equivarianti, un meccanismo di 
    attenzione, non-linearità e strati di normalizzazione.

    Vengono costruiti networks layers che sono equivarianti rispetto a \(E(3)\). 
    Una funzione \( f : \mathbb{G}_{3,0,1} \) è \( Pin(3,0,1) \)-equivariante rispetto
    alla rappresentazione \( p \) se 
    \[
        f(p_u(x)) = p_u(f(x))
    \]
    per ogni \( u \in Pin(3,0,1) \) e \(x \in \mathbb{G}_{3,0,1}\), dove \( p_u(x) \) è 
    il sandwich product definito in \eqref{eq:4}
\end{frame}

\begin{frame}{Trasformer}
    Per il GATr si è scelto di utilizzare l'architettura Transformer grazie alle sue 
    favorevoli proprietà di scalabilità, espressività, addestrabilità e versatilità.

    Di seguito si analizza più nel dettagli la struttura di questo modello.
\end{frame}

\begin{frame}{Principi di design}

    GATr è progettato per rappresentre vari oggetti e trasformazioni geometriche in 
    modo efficiente, permettendo il calcolo di diverse trasformazioni utilizzando pochi 
    strati e pochi dati. 

    GATr è stato progettato anche per essere simmetrico al gruppo di simmetria \(E(3)\),
    che include traslazioni, rotazioni e riflessioni. Permette quindi trasformazioni 
    arbitrarie sotto \(E(3)\), anche rispetto a traslazione degli input, permettendo di 
    rappresentare posizioni assolute. 

    GATr deve essere anche flessibile ripetto a più tipi di input geometrici, che vanno 
    da scene statiche a serie temporali. Il meccanismo di attenzione tramite prodotto 
    scalare, applicabile a più oggetti.

\end{frame}
\begin{frame}{Panoramica del Flusso di Lavoro di GATr}
    \begin{figure}
        \centering
        \includegraphics[width=1\textwidth]{../Images/GatrWorkflow.png}
    \end{figure}
    
    \textbf{Fasi del Flusso di Lavoro:}
    \begin{itemize}
        \item Se necessario gli input grezzi vengono preprocessati in tipi geometrici.
        \item Gli oggetti geometrici vengono incorporati in multivettori dell'algebra 
        geometrica \( G_{3,0,1} \), come descritto nella Figura \ref{fig:relazioneOggettiOperatori}.
        \item I dati multivettoriali vengono elaborati con una rete GATr.
    \end{itemize}
\end{frame}

\begin{frame}{Architettura di GATr}
    \begin{figure}
        \centering
        \includegraphics[width=1\textwidth]{../Images/GatrArchitecture.png}
        \caption{Architettura dettagliata di GATr.}
    \end{figure}
    
    L'architettura di GATr è composta da \( N \) blocchi trasformer, ognuno dei quali 
    include: un \textbf{LayerNorm} e un \textbf{meccanismo di auto-attenzione} per multivettori 
    equivarianti, una \textbf{connessione residua}, un altro LayerNorm, un \textbf{MLP con interazioni 
    bilineari geometriche} e una seconda connessione residua. 
    Dall’output di GATr si estraggono le variabili target, come illustrato in 
    Figura \ref{fig:relazioneOggettiOperatori}.
\end{frame}

\begin{frame}{LayerNorm - Layer Lineari}  
    Per preservare l’equivarianza, qualsiasi trasformazione lineare applicata ai 
    multivettori deve mantenere la coerenza sotto trasformazioni geometriche. 
    Qualsiasi \textbf{trasformazione lineare} 
    \( \phi : \mathbb{G}_{d,0,1} \rightarrow \mathbb{G}_{d,0,1} \) deve essere 
    della forma:

    \[
        \phi(x) = \sum_{k = 0}^{d+1} w_k {\langle x \rangle}_k + 
        \sum_{k = 0}^{d} v_k e_0 {\langle x \rangle}_k
    \]     

    \begin{itemize}
        \item La trasformazione combina diverse parti del multivettore, filtrate in base 
        al loro grado \( k \)
        \item \( w_k \) e \( v_k \) sono parametri apprendibili che controllano come 
        queste parti vengono combinate.
        \item \( e_0 \) funge da “base omogenea” per preservare la struttura geometrica.
    \end{itemize}
\end{frame}

\begin{frame}{Prodotti Geometrici Bilineari}
    Per permettere alla rete di costruire nuove caratteristiche geometriche da quelle 
    esistenti, come il vettore di traslazione tra due punti, sono necessarie due 
    primitive aggiuntive. 
    \begin{itemize}
        \item \textbf{Prodotto geometrico} \(x, y \rightarrow xy \), consente di mescolare fa 
        loro diversi tipi di componenti geometriche, come vettori e piani.
        \item \textbf{Join} \( \text{EquiJoin}(x,y,z) = z_{0123}(x^* \wedge y^*)^* \) operazione bilineare 
        che include il duale per rappresentare caratteristiche semplici come la distanza 
        euclidea. Il join viene reso equivariante anche rispetto alle riflessioni, 
        moltiplicandolo per un componente pseudoscalare di un multivettore \(z\)
    \end{itemize}
\end{frame}

\begin{frame}{Non-linearità e Normalizzazione}
    \textbf{Nonlinearità}: \\
    Utilizziamo la \textbf{Gated GELU} per introdurre non linearità: 
    \[
    \text{GatedGELU}(x) = \text{GELU}(x_1) \cdot x
    \]
    dove \(x_1\) è la componente scalare di \(x\).

    \textbf{Normalizzazione}: \\
    Definiamo una \textbf{LayerNorm equivariante}:
    \[
    \text{LayerNorm}(x) = \frac{x}{\sqrt{\mathbb{E}_c \langle x, x \rangle}}
    \]
    con il prodotto interno invariato \(\langle \cdot, \cdot \rangle\).

\end{frame}

\begin{frame}{Attenzione Multivettoriale Equivariante E(3)} 
    
\textbf{Attenzione multivettoriale equivariante}: \\
Dato un insieme di \textbf{query}, \textbf{key}, e \textbf{value} rappresentati 
da tensori multivettoriali, la \textbf{Attenzione E(3)-equivariant} è definita come:
\[
\text{Attention}(q, k, v)_{i' c'} = \sum_{i} \text{Softmax}_i 
\left( \frac{\sum_c\langle q_{i'c}, k_{ic} \rangle}{\sqrt{8n_c}} \right) v_{ic'}
\]
dove \(i\) e \(i'\) indicano gli oggetti (o token), \(c\) e \(c'\) indicano i canali, 
e \(\langle \cdot, \cdot \rangle\) è il prodotto interno invariato dell'algebra geometrica.

Il meccanismo utilizza il prodotto interno di \(G_{3,0,1}\), simile all'attenzione scalare 
nel trasformatore originale, ma applicato su 8 delle 16 dimensioni 
(escludendo le dimensioni contenenti \(e_0\)).

\end{frame}

\begin{frame}{Estensioni dell'Architettura GATr}
    Diverse estensioni possono essere applicate all'architettura di GATr per aumentarne 
    la flessibilità e l'espressività:
    
    \begin{itemize}
        \item \textbf{Rappresentazioni scalari ausiliarie:}  
        Integrazione di dati non geometrici, come codifiche posizionali, con scalari 
        aggiuntivi.
        
        \item \textbf{Attenzione basata sulla distanza:}  
        Meccanismo di attenzione che considera la distanza euclidea tra i punti per 
        migliorare l'espressività del modello.
        
        \item \textbf{Incorporamenti posizionali:}  
        Utilizzo di embedding posizionali rotanti per sequenze di oggetti.
        
        \item \textbf{Attenzione assiale:}  
        Gestione di dati su più dimensioni (oggetti, sequenze temporali) attraverso 
        attenzione assiale.
    \end{itemize}
    
    Queste estensioni ampliano le capacità di GATr, mantenendo i benefici di 
    equivarianza ed efficienza computazionale.
\end{frame}

\begin{frame}{Esperimenti}
    Si presentano una serie di esperimenti volti a dimostrare l'efficacia di 
    GATr in diversi ambiti. Questi esperimenti valutano le prestazioni di GATr 
    rispetto ad altri modelli, sia equivarianti che non, in termini di accuratezza, 
    efficienza dei dati e scalabilità.

    \begin{itemize}
        \item \textbf{ \( n \)-body dynamics, }
        \item \textbf{ Stima dello stress di parete su grandi mesh di arterie umane, }
        \item \textbf{ Pianificazione robotica tramite diffusione invariante, }
    \end{itemize}
\end{frame}

\begin{frame}{n -body dynamics}
    \begin{itemize}
        \item \textbf{Obiettivo:} Valutare la capacità di GATr di prevedere le posizioni finali di 
        corpi celesti (una stella e pianeti) in un sistema gravitazionale.
        \item \textbf{Dataset:} Dati sintetici generati con posizioni, velocità e masse campionate da 
        distribuzioni specifiche, con trasformazioni casuali per migliorare la generalizzazione.
        \item \textbf{Modelli di Confronto:}
        \begin{itemize}
            \item Transformer e MLP
            \item SEGNN, SE(3)-Transformer (modelli equivarianti)
            \item GCA-GNN (non equivariante)
        \end{itemize}
    \end{itemize}
    
\end{frame}

\begin{frame}{Risultati dell'Esperimento}
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{../Images/n-body.png}
        \caption{Errore nella previsione delle posizioni dei pianeti in funzione delle 
        dimensioni del dataset. A sinistra: senza spostamento di distribuzione; al centro: 
        con più pianeti di quelli addestrati; a destra: su dati traslati.}
    \end{figure}

    GATr supera i modelli di riferimento in efficienza dei dati, mostrando errori di 
    predizione più bassi con meno campioni. Generalizza bene anche su sistemi con più 
    pianeti e su dati traslati.
\end{frame}

\begin{frame}{Stima dello Stress di Parete nelle Arterie Umane}
    \begin{itemize}
        \item \textbf{Obiettivo:} Testare la scalabilità di GATr su mesh di grande 
        dimensione per stimare lo stress di parete nelle arterie umane, importante per 
        la formazione di aneurismi.
        \item \textbf{Dataset:} 2000 mesh di arterie, 1600 per l'addestramento e 400 
        per la valutazione.
        \item \textbf{Modelli di Confronto:}
        \begin{itemize}
            \item Transformer, PointNet++
            \item GEM-CNN (modello equivariante)
        \end{itemize}
    \end{itemize}
\end{frame}
    
\begin{frame}
    \frametitle{Risultati dell'Esperimento}
    \begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{../Images/arteries.png}
    \end{figure}
    
        \textbf{GATr} supera tutti i modelli di riferimento in termini di accuratezza e 
        di efficienza nell'utilizzo dei dati, sia su dati non canonizzati 
        (con mesh ruotate casualmente) che su dati canonizzati 
        (con mesh orientate nella stessa direzione).
\end{frame}

\begin{frame}{Pianificazione Robotica tramite Diffusione Invariante}
    \begin{itemize}
        \item \textbf{Obiettivo:} Usare GAT come Diffuser \(E(3)\)-invariante per 
        la pianificazione robotica. 
        \item \textbf{Compito:} Un braccio robotico Kuka deve impilare blocchi su un 
        tavolo. Il reward è la probabilità di successo.
        \item \textbf{Dataset:} 11,000 dimostrazioni effettuate in precedenza
        \item \textbf{Modelli di Confronto:}
        \begin{itemize}
            \item Modelli di diffusione tradizionali (Diffuser, Transformer)
            \item EDGI (modello equivariante)
            \item CQL e BCQ (algoritmi di apprendimento per rinforzo offline)
        \end{itemize}
    \end{itemize}
    
\end{frame}
    
\begin{frame}{Risultati dell'Esperimento}
    \begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{../Images/Kena.png}
    \end{figure}

    GATr-Diffuser supera tutti i modelli di riferimento nel compito di impilamento dei 
    blocchi, dimostrando una maggiore efficienza nell'utilizzo dei dati e ottenendo 
    risultati migliori con un minor numero di traiettorie di addestramento.
\end{frame}
    
\begin{frame}{Conclusioni}
    \begin{itemize}
        \item GATr si dimostra versatile ed efficace in vari contesti applicativi:
        \begin{itemize}
            \item Previsione di sistemi dinamici complessi.
            \item Gestione di grandi set di dati geometrici.
            \item Pianificazione robotica più efficiente.
        \end{itemize}
        \item GATr rappresenta un importante passo avanti nell'elaborazione di 
        dati geometrici tramite deep learning.
    \end{itemize}
\end{frame}
\begin{frame}{Bibliografia}
   \begin{itemize}
       \item Johann Brehmer, Pim de Haan, Sönke Behrends, Taco Cohen
           \emph{Geometric Algebra Transformer},
           Conference on Neural Information Processing Systems.
   \end{itemize} 
\end{frame}
